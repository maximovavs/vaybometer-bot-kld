#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
gpt.py

–û–±—ë—Ä—Ç–∫–∞ –¥–ª—è LLM-–≤—ã–∑–æ–≤–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±–ª–æ–∫–∞ ¬´–í—ã–≤–æ–¥ / –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏¬ª.

–¶–µ–ª–∏ (–ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É):
- –ü–æ—Ä—è–¥–æ–∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤: OpenAI ‚Üí Gemini ‚Üí Groq.
- OpenAI –ø—Ä–æ–±—É–µ–º –û–î–ò–ù —Ä–∞–∑: –µ—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ 429/insufficient_quota, –æ—Ç–∫–ª—é—á–∞–µ–º OpenAI –¥–æ –∫–æ–Ω—Ü–∞ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞
  (—á—Ç–æ–±—ã –Ω–µ ¬´—Å—Ç—É—á–∞—Ç—å¬ª –ø–æ–≤—Ç–æ—Ä–Ω–æ –ø–æ –∫–∞–∂–¥–æ–º—É –≤—ã–∑–æ–≤—É gpt_complete()).
- Gemini: –ø–µ—Ä–µ–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª–∏ –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ, –Ω–æ —Å–Ω–∞—á–∞–ª–∞ —Å–≤–µ—Ä—è–µ–º—Å—è —Å–æ —Å–ø–∏—Å–∫–æ–º –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π,
  —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–∞—Ç–∏—Ç—å –≤—Ä–µ–º—è –Ω–∞ –∑–∞–≤–µ–¥–æ–º–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ (404).
- Groq: –∫–∞–∫ —Ä–∞–Ω—å—à–µ ‚Äî –ø–µ—Ä–µ–±–æ—Ä –º–æ–¥–µ–ª–µ–π.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è:
- OPENAI_API_KEY (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- GEMINI_API_KEY (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
- GROQ_API_KEY (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

Gemini OpenAI-compat endpoint:
- —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π:  GET  https://generativelanguage.googleapis.com/v1beta/openai/models?key=...
- —á–∞—Ç:            POST https://generativelanguage.googleapis.com/v1beta/openai/chat/completions?key=...

–ù–∞—Å—Ç—Ä–æ–π–∫–∏:
- GEMINI_MODELS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ): —Å–ø–∏—Å–æ–∫ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –Ω–∞–ø—Ä–∏–º–µ—Ä:
  "gemini-3-flash,gemini-3-pro,gemini-2.5-flash,gemini-3-flash-preview"
- GROQ_MODELS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ): —Å–ø–∏—Å–æ–∫ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–µ—Ñ–æ–ª—Ç.
"""

from __future__ import annotations

import logging
import os
import random
from typing import Dict, List, Optional, Tuple

log = logging.getLogger(__name__)

try:
    from openai import OpenAI  # type: ignore
except Exception:
    OpenAI = None  # type: ignore

try:
    import requests  # type: ignore
except Exception:
    requests = None  # type: ignore

# ‚îÄ‚îÄ –∫–ª—é—á–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
OPENAI_KEY = os.getenv("OPENAI_API_KEY") or ""
GEMINI_KEY = os.getenv("GEMINI_API_KEY") or ""
GROQ_KEY = os.getenv("GROQ_API_KEY") or ""

# ‚îÄ‚îÄ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Gemini (–ø–æ –≤–∞—à–µ–º—É –ø–æ—Ä—è–¥–∫—É) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
_DEFAULT_GEMINI_PREF = [
    "gemini-3-flash",
    "gemini-3-pro",
    "gemini-2.5-flash",
    "gemini-3-flash-preview",
]
_GEMINI_PREF = [
    m.strip() for m in (os.getenv("GEMINI_MODELS") or ",".join(_DEFAULT_GEMINI_PREF)).split(",")
    if m.strip()
]

# ‚îÄ‚îÄ –º–æ–¥–µ–ª–∏ Groq ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
_DEFAULT_GROQ_MODELS = [
    "moonshotai/kimi-k2-instruct-0905",
    "llama-3.3-70b-versatile",
    "llama-3.1-8b-instant",
    "gemma2-9b-it",
    "qwen/qwen3-32b",
    "deepseek-r1-distill-llama-70b",
]
_GROQ_MODELS = [
    m.strip() for m in (os.getenv("GROQ_MODELS") or ",".join(_DEFAULT_GROQ_MODELS)).split(",")
    if m.strip()
]

# ‚îÄ‚îÄ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã (—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
PROVIDER_ORDER = [p for p in ("openai", "gemini", "groq")]

# ‚îÄ‚îÄ ¬´–æ–¥–∏–Ω —Ä–∞–∑¬ª / –∫—ç—à –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–º–∫–∞—Ö –∑–∞–ø—É—Å–∫–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
_OPENAI_DISABLED = False
_OPENAI_DISABLED_REASON = ""

_GEMINI_DISABLED = False
_GEMINI_DISABLED_REASON = ""

_GEMINI_AVAILABLE: Optional[set[str]] = None          # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ id (–±–µ–∑ "models/")
_GEMINI_MODELS_FETCHED = False
_GEMINI_UNSUPPORTED: set[str] = set()                 # –º–æ–¥–µ–ª–∏, –ø–æ –∫–æ—Ç–æ—Ä—ã–º –ø–æ–ª—É—á–∏–ª–∏ 404/unsupported


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _looks_like_quota_or_429(err_text: str) -> bool:
    t = (err_text or "").lower()
    return any(k in t for k in ("insufficient_quota", "rate limit", "429", "quota"))


def _looks_like_model_not_found(err_text: str) -> bool:
    t = (err_text or "").lower()
    return ("not found" in t) or ("model" in t and "not" in t and "found" in t) or ("404" in t)


def _openai_client() -> Optional["OpenAI"]:
    """
    –ö–ª–∏–µ–Ω—Ç OpenAI —Å –æ—Ç–∫–ª—é—á—ë–Ω–Ω—ã–º–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–º–∏ —Ä–µ—Ç—Ä–∞—è–º–∏:
    –ø—Ä–∏ 429/insufficient_quota –±—ã—Å—Ç—Ä–æ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –¥–∞–ª—å—à–µ.
    """
    if _OPENAI_DISABLED:
        return None
    if not OPENAI_KEY or not OpenAI:
        return None
    try:
        return OpenAI(api_key=OPENAI_KEY, timeout=20.0, max_retries=0)
    except Exception as e:
        log.warning("OpenAI client init error: %s", e)
        return None


def _groq_client() -> Optional["OpenAI"]:
    """
    OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è Groq —á–µ—Ä–µ–∑ base_url.
    """
    if not GROQ_KEY or not OpenAI:
        return None
    try:
        return OpenAI(
            api_key=GROQ_KEY,
            base_url="https://api.groq.com/openai/v1",
            timeout=25.0,
            max_retries=0,
        )
    except Exception as e:
        log.warning("Groq client init error: %s", e)
        return None


def _gemini_base_url() -> str:
    # OpenAI-compat —É Gemini
    return "https://generativelanguage.googleapis.com/v1beta/openai"


def _norm_gemini_model_id(mid: str) -> str:
    """
    –í —Å–ø–∏—Å–∫–µ –º–æ–¥–µ–ª–µ–π Gemini –∏–Ω–æ–≥–¥–∞ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è "models/<name>" ‚Äî –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ "<name>".
    –¢–∞–∫–∂–µ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –±–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç –ø—É—Ç–∏.
    """
    mid = (mid or "").strip()
    if not mid:
        return mid
    if "/" in mid:
        mid = mid.split("/")[-1].strip()
    return mid


def _gemini_list_models() -> set[str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π Gemini (OpenAI-compat) –∏ –∫–µ—à–∏—Ä—É–µ—Ç –µ–≥–æ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö id.
    """
    global _GEMINI_AVAILABLE, _GEMINI_MODELS_FETCHED, _GEMINI_DISABLED, _GEMINI_DISABLED_REASON

    if _GEMINI_AVAILABLE is not None:
        return _GEMINI_AVAILABLE

    _GEMINI_AVAILABLE = set()
    _GEMINI_MODELS_FETCHED = True

    if _GEMINI_DISABLED:
        return _GEMINI_AVAILABLE
    if not GEMINI_KEY or not requests:
        return _GEMINI_AVAILABLE

    try:
        url = f"{_gemini_base_url()}/models"
        resp = requests.get(url, params={"key": GEMINI_KEY}, timeout=20)
        if resp.status_code != 200:
            body = (resp.text or "")[:300].replace("\n", " ")
            log.warning("Gemini models.list() failed (%s): %s", resp.status_code, body)
            # –µ—Å–ª–∏ –∫–ª—é—á/–¥–æ—Å—Ç—É–ø–∞ –Ω–µ—Ç ‚Äî –æ—Ç–∫–ª—é—á–∞–µ–º Gemini –¥–æ –∫–æ–Ω—Ü–∞ –∑–∞–ø—É—Å–∫–∞
            if resp.status_code in (401, 403):
                _GEMINI_DISABLED = True
                _GEMINI_DISABLED_REASON = f"http {resp.status_code}"
            return _GEMINI_AVAILABLE

        data = resp.json() or {}
        models = data.get("data") or data.get("models") or []
        # OpenAI-compat –º–æ–∂–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å: {"data":[{"id":"models/gemini-2.5-flash", ...}, ...]}
        for m in models:
            mid = _norm_gemini_model_id(str(m.get("id") or m.get("name") or ""))
            if mid:
                _GEMINI_AVAILABLE.add(mid)

        log.info("Gemini models.list(): %s models", len(_GEMINI_AVAILABLE))
        return _GEMINI_AVAILABLE

    except Exception as e:
        log.warning("Gemini models.list() exception: %s", e)
        return _GEMINI_AVAILABLE


def _gemini_chat(
    messages: List[dict],
    model: str,
    temperature: float,
    max_tokens: int,
) -> str:
    """
    OpenAI-compat chat/completions –¥–ª—è Gemini.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–ª–∏ "".
    """
    if _GEMINI_DISABLED or not GEMINI_KEY or not requests:
        return ""

    url = f"{_gemini_base_url()}/chat/completions"
    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
    }
    resp = requests.post(url, params={"key": GEMINI_KEY}, json=payload, timeout=25)

    if resp.status_code == 200:
        data = resp.json() or {}
        choices = data.get("choices") or []
        if choices:
            msg = (choices[0].get("message") or {}).get("content") or ""
            return str(msg).strip()
        return ""

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
    body = (resp.text or "")[:300].replace("\n", " ")
    if resp.status_code == 404 or "not found" in body.lower():
        raise RuntimeError(f"MODEL_NOT_FOUND: {model}: http {resp.status_code} {body}")
    if resp.status_code in (401, 403):
        raise RuntimeError(f"AUTH_ERROR: http {resp.status_code} {body}")
    if resp.status_code == 429:
        raise RuntimeError(f"RATE_LIMIT: http 429 {body}")

    raise RuntimeError(f"Gemini http {resp.status_code}: {body}")


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ main wrapper ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def gpt_complete(
    prompt: str,
    system: Optional[str] = None,
    temperature: float = 0.7,
    max_tokens: int = 600,
) -> str:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ LLM. –ü—Ä–æ–±—É–µ—Ç –ø–æ –æ—á–µ—Ä–µ–¥–∏: OpenAI ‚Üí Gemini ‚Üí Groq.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç text –∏–ª–∏ "" (–µ—Å–ª–∏ –≤—Å—ë –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ).
    """
    global _OPENAI_DISABLED, _OPENAI_DISABLED_REASON, _GEMINI_DISABLED, _GEMINI_DISABLED_REASON

    # –°–æ–æ–±—â–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
    messages: List[dict] = []
    if system:
        messages.append({"role": "system", "content": system})
    messages.append({"role": "user", "content": prompt})

    text = ""

    # 1) OpenAI (—Ä–æ–≤–Ω–æ –æ–¥–∏–Ω ¬´–ø–µ—Ä–≤—ã–π —É–¥–∞—Ä¬ª; –ø–æ—Å–ª–µ 429/–∫–≤–æ—Ç—ã –æ—Ç–∫–ª—é—á–∞–µ–º –¥–æ –∫–æ–Ω—Ü–∞ –∑–∞–ø—É—Å–∫–∞)
    if "openai" in PROVIDER_ORDER and not text and not _OPENAI_DISABLED:
        cli = _openai_client()
        if cli:
            try:
                r = cli.chat.completions.create(
                    model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens,
                )
                text = (r.choices[0].message.content or "").strip()
                if text:
                    return text
            except Exception as e:
                msg = str(e)
                if _looks_like_quota_or_429(msg):
                    # –∫–ª—é—á–µ–≤–∞—è –ø—Ä–∞–≤–∫–∞: –±–æ–ª—å—à–µ –Ω–µ –ø—ã—Ç–∞–µ–º—Å—è OpenAI –≤ —ç—Ç–æ–º –∑–∞–ø—É—Å–∫–µ
                    _OPENAI_DISABLED = True
                    _OPENAI_DISABLED_REASON = msg[:200]
                    log.warning("OpenAI quota/rate-limit ‚Üí disable for this run: %s", msg)
                else:
                    log.warning("OpenAI error: %s", e)

    # 2) Gemini (–ø–µ—Ä–µ–±–æ—Ä –º–æ–¥–µ–ª–µ–π; –∏–∑–±–µ–≥–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö 404 –∏ —É—á–∏—Ç—ã–≤–∞–µ–º models.list)
    if "gemini" in PROVIDER_ORDER and not text and not _GEMINI_DISABLED and GEMINI_KEY and requests:
        # —É–∑–Ω–∞—ë–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –≤—Å—ë —Ä–∞–≤–Ω–æ –ø–æ–ø—Ä–æ–±—É–µ–º –∫–∞–∫ –µ—Å—Ç—å, –Ω–æ —Å –∫–µ—à–µ–º 404)
        avail = _gemini_list_models()

        models_to_try = _GEMINI_PREF[:]
        # –µ—Å–ª–∏ —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –Ω–µ–ø—É—Å—Ç–æ–π ‚Äî —Ñ–∏–ª—å—Ç—Ä—É–µ–º
        if avail:
            models_to_try = [m for m in models_to_try if _norm_gemini_model_id(m) in avail] or models_to_try

        for mdl in models_to_try:
            mdl_norm = _norm_gemini_model_id(mdl)
            if mdl_norm in _GEMINI_UNSUPPORTED:
                continue

            try:
                out = _gemini_chat(messages, mdl_norm, temperature, max_tokens)
                if out:
                    log.info("LLM: Gemini ok (model=%s)", mdl_norm)
                    return out
                log.warning("Gemini: empty response (model=%s)", mdl_norm)
            except Exception as e:
                em = str(e)
                if em.startswith("MODEL_NOT_FOUND") or _looks_like_model_not_found(em):
                    _GEMINI_UNSUPPORTED.add(mdl_norm)
                    log.warning("Gemini model %s not found/unsupported, trying next.", mdl_norm)
                    continue
                if em.startswith("AUTH_ERROR"):
                    _GEMINI_DISABLED = True
                    _GEMINI_DISABLED_REASON = em[:200]
                    log.warning("Gemini auth error ‚Üí disable for this run: %s", em)
                    break
                if em.startswith("RATE_LIMIT") or _looks_like_quota_or_429(em):
                    log.warning("Gemini rate-limit/quota on %s ‚Üí switch to next provider.", mdl_norm)
                    break

                log.warning("Gemini error on %s: %s", mdl_norm, e)
                continue

    # 3) Groq (–∫–∞–∫ —Ä–∞–Ω—å—à–µ, –ø–µ—Ä–µ–±–æ—Ä –º–æ–¥–µ–ª–µ–π)
    if "groq" in PROVIDER_ORDER and not text:
        cli = _groq_client()
        if cli:
            for mdl in _GROQ_MODELS:
                try:
                    r = cli.chat.completions.create(
                        model=mdl,
                        messages=messages,
                        temperature=temperature,
                        max_tokens=max_tokens,
                    )
                    text = (r.choices[0].message.content or "").strip()
                    if text:
                        log.info("LLM: Groq ok (model=%s)", mdl)
                        return text
                except Exception as e:
                    msg = str(e).lower()
                    if "decommissioned" in msg or ("model" in msg and "not found" in msg):
                        log.warning("Groq model %s decommissioned/not found, trying next.", mdl)
                        continue
                    if "rate limit" in msg or "429" in msg:
                        log.warning("Groq rate limit on %s, trying next.", mdl)
                        continue
                    log.warning("Groq error on %s: %s", mdl, e)
                    continue

    return ""


# ‚îÄ‚îÄ —Å–ª–æ–≤–∞—Ä–∏ —Ñ–æ–ª–±—ç–∫–æ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CULPRITS: Dict[str, Dict[str, object]] = {
    "—Ç—É–º–∞–Ω": {
        "emoji": "üåÅ",
        "tips": [
            "üî¶ –°–≤–µ—Ç–ª–∞—è –æ–¥–µ–∂–¥–∞ –∏ —Ñ–æ–Ω–∞—Ä—å",
            "üöó –í–æ–¥–∏—Ç–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ",
            "‚è∞ –ü–ª–∞–Ω–∏—Ä—É–π—Ç–µ –ø–æ–µ–∑–¥–∫–∏ –∑–∞—Ä–∞–Ω–µ–µ",
            "üï∂Ô∏è –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ—á–∫–∏ –ø—Ä–æ—Ç–∏–≤ –±–ª–∏–∫–æ–≤",
        ],
    },
    "–º–∞–≥–Ω–∏—Ç–Ω—ã–µ –±—É—Ä–∏": {
        "emoji": "üß≤",
        "tips": [
            "üßò 5-–º–∏–Ω—É—Ç–Ω–∞—è –¥—ã—Ö–∞—Ç–µ–ª—å–Ω–∞—è –ø–∞—É–∑–∞",
            "üåø –ó–∞–≤–∞—Ä–∏—Ç–µ —á–∞–π —Å —Ç—Ä–∞–≤–∞–º–∏",
            "üôÖ –ò–∑–±–µ–≥–∞–π—Ç–µ —Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π",
            "üòå –õ—ë–≥–∫–∞—è —Ä–∞—Å—Ç—è–∂–∫–∞ –ø–µ—Ä–µ–¥ —Å–Ω–æ–º",
        ],
    },
    "–Ω–∏–∑–∫–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ": {
        "emoji": "üå°Ô∏è",
        "tips": [
            "üíß –ü–µ–π—Ç–µ –±–æ–ª—å—à–µ –≤–æ–¥—ã",
            "üò¥ 20-–º–∏–Ω—É—Ç–Ω—ã–π –¥–Ω–µ–≤–Ω–æ–π –æ—Ç–¥—ã—Ö",
            "ü§∏ –õ—ë–≥–∫–∞—è –∑–∞—Ä—è–¥–∫–∞ —É—Ç—Ä–æ–º",
            "ü•ó –õ—ë–≥–∫–∏–π —É–∂–∏–Ω –±–µ–∑ —Å–æ–ª–∏",
        ],
    },
    "—à–∞–ª—å–Ω–æ–π –≤–µ—Ç–µ—Ä": {
        "emoji": "üí®",
        "tips": [
            "üß£ –ó–∞—Ö–≤–∞—Ç–∏—Ç–µ —à–∞—Ä—Ñ",
            "üö∂ –ö–æ—Ä–æ—Ç–∫–∞—è –ø—Ä–æ–≥—É–ª–∫–∞",
            "üï∂Ô∏è –ó–∞—â–∏—Ç–∏—Ç–µ –≥–ª–∞–∑–∞ –æ—Ç –ø—ã–ª–∏",
            "üå≥ –ò–∑–±–µ–≥–∞–π—Ç–µ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤",
        ],
    },
    "–∂–∞—Ä–∞": {
        "emoji": "üî•",
        "tips": [
            "üí¶ –î–µ—Ä–∂–∏—Ç–µ –±—É—Ç—ã–ª–∫—É –≤–æ–¥—ã —Ä—è–¥–æ–º",
            "üß¢ –ù–æ—Å–∏—Ç–µ –≥–æ–ª–æ–≤–Ω–æ–π —É–±–æ—Ä",
            "üå≥ –ò—â–∏—Ç–µ —Ç–µ–Ω—å –≤ –ø–æ–ª–¥–µ–Ω—å",
            "‚ùÑÔ∏è –ü—Ä–æ—Ö–ª–∞–¥–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å –Ω–∞ –ª–æ–±",
        ],
    },
    "—Å—ã—Ä–æ—Å—Ç—å": {
        "emoji": "üíß",
        "tips": [
            "üëü –°–º–µ–Ω–∏—Ç–µ –æ–±—É–≤—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏",
            "üåÇ –î–µ—Ä–∂–∏—Ç–µ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∑–æ–Ω—Ç",
            "üå¨Ô∏è –ü—Ä–æ–≤–µ—Ç—Ä–∏–≤–∞–π—Ç–µ –∂–∏–ª–∏—â–µ",
            "üß• –õ—ë–≥–∫–∞—è –Ω–µ–ø—Ä–æ–º–æ–∫–∞–µ–º–∞—è –∫—É—Ä—Ç–∫–∞",
        ],
    },
    "–ø–æ–ª–Ω–∞—è –ª—É–Ω–∞": {
        "emoji": "üåï",
        "tips": [
            "üìù –ó–∞–ø–∏—à–∏—Ç–µ —è—Ä–∫–∏–µ –∏–¥–µ–∏ –ø–µ—Ä–µ–¥ —Å–Ω–æ–º",
            "üßò –ú—è–≥–∫–∞—è –º–µ–¥–∏—Ç–∞—Ü–∏—è –≤–µ—á–µ—Ä–æ–º",
            "üåô –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ –ª—É–Ω—É –±–µ–∑ –≥–∞–¥–∂–µ—Ç–æ–≤",
            "üìö –ß—Ç–µ–Ω–∏–µ –Ω–∞ —Å–≤–µ–∂–µ–º –≤–æ–∑–¥—É—Ö–µ",
        ],
    },
    "–º–∏–Ω–∏-–ø–∞—Ä–∞–¥ –ø–ª–∞–Ω–µ—Ç": {
        "emoji": "‚ú®",
        "tips": [
            "üî≠ –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ –Ω–µ–±–æ –Ω–∞ —Ä–∞—Å—Å–≤–µ—Ç–µ",
            "üì∏ –°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –∑–∞–∫–∞—Ç–∞",
            "ü§î –ü–æ–¥—É–º–∞–π—Ç–µ –æ –±–µ—Å–∫—Ä–∞–π–Ω–∏—Ö –ø—Ä–æ—Å—Ç–æ—Ä–∞—Ö",
            "üé∂ –°–ª—É—à–∞–π—Ç–µ —Å–ø–æ–∫–æ–π–Ω—É—é –º—É–∑—ã–∫—É –≤–µ—á–µ—Ä–æ–º",
        ],
    },
}

ASTRO_HEALTH_FALLBACK: List[str] = [
    "üí§ –°–æ–±–ª—é–¥–∞–π—Ç–µ —Ä–µ–∂–∏–º —Å–Ω–∞: –ª–æ–∂–∏—Ç–µ—Å—å –Ω–µ –ø–æ–∑–∂–µ 23:00",
    "ü•¶ –í–∫–ª—é—á–∏—Ç–µ –≤ —Ä–∞—Ü–∏–æ–Ω —Å–≤–µ–∂–∏–µ –æ–≤–æ—â–∏ –∏ –∑–µ–ª–µ–Ω—å",
    "ü•õ –ü–µ–π—Ç–µ —Ç—ë–ø–ª–æ–µ –º–æ–ª–æ–∫–æ —Å –º—ë–¥–æ–º –ø–µ—Ä–µ–¥ —Å–Ω–æ–º",
    "üßò –î–µ–ª–∞–π—Ç–µ –ª—ë–≥–∫—É—é —Ä–∞—Å—Ç—è–∂–∫—É —É—Ç—Ä–æ–º –∏ –≤–µ—á–µ—Ä–æ–º",
    "üö∂ –ü—Ä–æ–≥—É–ª–∏–≤–∞–π—Ç–µ—Å—å 20 –º–∏–Ω—É—Ç –Ω–∞ —Å–≤–µ–∂–µ–º –≤–æ–∑–¥—É—Ö–µ",
]


# ‚îÄ‚îÄ –ø—É–±–ª–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è ¬´–í—ã–≤–æ–¥/–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏¬ª ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def gpt_blurb(culprit: str) -> Tuple[str, List[str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (summary: str, tips: List[str]) ‚Äî –∫–æ–Ω—Ç—Ä–∞–∫—Ç –∫–∞–∫ —Ä–∞–Ω—å—à–µ.
    """
    culprit_lower = culprit.lower().strip()

    def _make_prompt(cul: str, astro: bool) -> str:
        if astro:
            return (
                "–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π health coach —Å–æ –∑–Ω–∞–Ω–∏—è–º–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—ã, "
                "–∫–æ—Ç–æ—Ä—ã–π –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏–∑—É—á–∞–µ—Ç —á—Ç–æ-—Ç–æ –Ω–æ–≤–æ–µ, –Ω–æ –ø–∏—à–µ—Ç –≥—Ä–∞–º–æ—Ç–Ω–æ. "
                f"–ù–∞–ø–∏—à–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π: ¬´–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {cul}!¬ª. "
                "–ü–æ—Å–ª–µ —Ç–æ—á–∫–∏ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–π –ø–æ–∑–∏—Ç–∏–≤ ‚â§12 —Å–ª–æ–≤ –¥–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤. –ù–µ –ø–∏—à–∏ —Å–∞–º–æ —Å–ª–æ–≤–æ ¬´—Å–æ–≤–µ—Ç¬ª. "
                "–ó–∞—Ç–µ–º –¥–∞–π —Ä–æ–≤–Ω–æ 3 —Å–æ–≤–µ—Ç–∞ (—Å–æ–Ω, –ø–∏—Ç–∞–Ω–∏–µ, –¥—ã—Ö–∞–Ω–∏–µ/–ª—ë–≥–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å) "
                "‚â§12 —Å–ª–æ–≤ —Å —ç–º–æ–¥–∑–∏. –û—Ç–≤–µ—Ç ‚Äî –ø–æ —Å—Ç—Ä–æ–∫–∞–º."
            )
        return (
            "–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π health coach —Å–æ –∑–Ω–∞–Ω–∏—è–º–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—ã, "
            "–∫–æ—Ç–æ—Ä—ã–π –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏–∑—É—á–∞–µ—Ç —á—Ç–æ-—Ç–æ –Ω–æ–≤–æ–µ, –Ω–æ –ø–∏—à–µ—Ç –≥—Ä–∞–º–æ—Ç–Ω–æ. "
            f"–ù–∞–ø–∏—à–∏ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π: ¬´–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {cul}!¬ª. "
            "–ü–æ—Å–ª–µ —Ç–æ—á–∫–∏ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–π –ø–æ–∑–∏—Ç–∏–≤ ‚â§12 —Å–ª–æ–≤ –¥–ª—è –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤. "
            "–ó–∞—Ç–µ–º –¥–∞–π —Ä–æ–≤–Ω–æ 3 —Å–æ–≤–µ—Ç–∞ –ø–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω–µ "
            "(–ø–∏—Ç–∞–Ω–∏–µ, —Å–æ–Ω, –ª—ë–≥–∫–∞—è —Ñ–∏–∑–∏—á–µ—Å–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å) ‚â§12 —Å–ª–æ–≤ —Å —ç–º–æ–¥–∑–∏. "
            "–ù–µ –ø–∏—à–∏ —Å–∞–º–æ —Å–ª–æ–≤–æ ¬´—Å–æ–≤–µ—Ç¬ª. –û—Ç–≤–µ—Ç ‚Äî –ø–æ —Å—Ç—Ä–æ–∫–∞–º."
        )

    def _from_lines(cul: str, lines: List[str], fallback_pool: List[str]) -> Tuple[str, List[str]]:
        summary = lines[0] if lines else f"–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {cul}! üòâ"
        tips = [ln for ln in lines[1:] if ln][:3]
        if len(tips) < 2:
            remaining = [t for t in fallback_pool if t not in tips]
            if remaining:
                tips += random.sample(remaining, min(3 - len(tips), len(remaining)))
        return summary, tips[:3]

    # 1) ¬´–ü–æ–≥–æ–¥–Ω—ã–π¬ª —Ñ–∞–∫—Ç–æ—Ä –∏–∑ —Å–ª–æ–≤–∞—Ä—è CULPRITS
    if culprit_lower in CULPRITS:
        tips_pool = CULPRITS[culprit_lower]["tips"]  # type: ignore[index]
        prompt = _make_prompt(culprit, astro=False)
        text = gpt_complete(prompt=prompt, system=None, temperature=0.7, max_tokens=500)
        if not text:
            summary = f"–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {culprit}! üòâ"
            return summary, random.sample(list(tips_pool), min(3, len(tips_pool)))  # type: ignore[arg-type]
        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
        return _from_lines(culprit, lines, list(tips_pool))  # type: ignore[arg-type]

    # 2) ¬´–ê—Å—Ç—Ä–æ—Ñ–∞–∫—Ç–æ—Ä¬ª
    astro_keywords = ["–ª—É–Ω–∞", "–Ω–æ–≤–æ–ª—É–Ω–∏–µ", "–ø–æ–ª–Ω–æ–ª—É–Ω–∏–µ", "—á–µ—Ç–≤–µ—Ä—Ç—å"]
    is_astro = any(k in culprit_lower for k in astro_keywords)
    if is_astro:
        prompt = _make_prompt(culprit, astro=True)
        text = gpt_complete(prompt=prompt, system=None, temperature=0.7, max_tokens=500)
        if not text:
            summary = f"–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {culprit}! üòâ"
            return summary, random.sample(ASTRO_HEALTH_FALLBACK, 3)
        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
        return _from_lines(culprit, lines, ASTRO_HEALTH_FALLBACK)

    # 3) –û–±—â–∏–π —Å–ª—É—á–∞–π
    prompt = _make_prompt(culprit, astro=True)
    text = gpt_complete(prompt=prompt, system=None, temperature=0.7, max_tokens=500)
    if not text:
        summary = f"–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {culprit}! üòâ"
        return summary, random.sample(ASTRO_HEALTH_FALLBACK, 3)
    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
    fallback_pool = ASTRO_HEALTH_FALLBACK + sum((c["tips"] for c in CULPRITS.values()), [])  # type: ignore[list-item]
    return _from_lines(culprit, lines, fallback_pool)
