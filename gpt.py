#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
gpt.py ‚Äî —Å–æ–≤–µ—Ç—ã/–≤—ã–≤–æ–¥ —Å LLM –∏ –º—è–≥–∫–∏–º —Ñ–æ–ª–±—ç–∫–æ–º.

–ü–æ–≤–µ–¥–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ:
- –í–Ω–µ—à–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è gpt_blurb(culprit) -> (summary, tips)
- –ü—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ LLM –æ—Å—Ç–∞—é—Ç—Å—è –ø—Ä–µ–∂–Ω–∏–µ —Ñ–æ–ª–±—ç–∫–∏.

–ù–æ–≤–æ–µ:
- –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ñ–æ–ª–±—ç–∫-–ø–æ—Ä—è–¥–æ–∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤: OpenAI -> Gemini -> Groq
- ENV-–º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º—ã: OPENAI_MODEL / GEMINI_MODEL / GROQ_MODEL
"""

from __future__ import annotations
import os
import random
import logging
from typing import Tuple, List, Optional

# ‚îÄ‚îÄ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã (–ª–µ–Ω–∏–≤—ã–µ –∏–º–ø–æ—Ä—Ç—ã –Ω–∏–∂–µ) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
try:
    from openai import OpenAI  # type: ignore
except Exception:
    OpenAI = None  # noqa: N816

try:
    import google.generativeai as genai  # type: ignore
except Exception:
    genai = None  # type: ignore

try:
    from groq import Groq  # type: ignore
except Exception:
    Groq = None  # type: ignore

# ‚îÄ‚îÄ –∫–ª—é—á–∏ –∏ –º–æ–¥–µ–ª–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
OPENAI_KEY  = os.getenv("OPENAI_API_KEY", "")
GEMINI_KEY  = os.getenv("GEMINI_API_KEY", "")
GROQ_KEY    = os.getenv("GROQ_API_KEY", "")

OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
GROQ_MODEL   = os.getenv("GROQ_MODEL",   "llama-3.1-70b-versatile")

# ‚îÄ‚îÄ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ç–∏—Ö–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
log = logging.getLogger(__name__)
if not log.handlers:
    logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")

# ‚îÄ‚îÄ —Ñ–æ–ª–±—ç–∫–∏ –∫–∞–∫ —É —Ç–µ–±—è —Ä–∞–Ω—å—à–µ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CULPRITS = {
    "—Ç—É–º–∞–Ω": {
        "emoji": "üåÅ",
        "tips": [
            "üî¶ –°–≤–µ—Ç–ª–∞—è –æ–¥–µ–∂–¥–∞ –∏ —Ñ–æ–Ω–∞—Ä—å",
            "üöó –í–æ–¥–∏—Ç–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ",
            "‚è∞ –ü–ª–∞–Ω–∏—Ä—É–π—Ç–µ –ø–æ–µ–∑–¥–∫–∏ –∑–∞—Ä–∞–Ω–µ–µ",
            "üï∂Ô∏è –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ—á–∫–∏ –ø—Ä–æ—Ç–∏–≤ –±–ª–∏–∫–æ–≤",
        ],
    },
    "–º–∞–≥–Ω–∏—Ç–Ω—ã–µ –±—É—Ä–∏": {
        "emoji": "üß≤",
        "tips": [
            "üßò 5-–º–∏–Ω—É—Ç–Ω–∞—è –¥—ã—Ö–∞—Ç–µ–ª—å–Ω–∞—è –ø–∞—É–∑–∞",
            "üåø –ó–∞–≤–∞—Ä–∏—Ç–µ —á–∞–π —Å —Ç—Ä–∞–≤–∞–º–∏",
            "üôÖ –ò–∑–±–µ–≥–∞–π—Ç–µ —Å—Ç—Ä–µ—Å—Å–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π",
            "üòå –õ—ë–≥–∫–∞—è —Ä–∞—Å—Ç—è–∂–∫–∞ –ø–µ—Ä–µ–¥ —Å–Ω–æ–º",
        ],
    },
    "–Ω–∏–∑–∫–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ": {
        "emoji": "üå°Ô∏è",
        "tips": [
            "üíß –ü–µ–π—Ç–µ –±–æ–ª—å—à–µ –≤–æ–¥—ã",
            "üò¥ 20-–º–∏–Ω—É—Ç–Ω—ã–π –¥–Ω–µ–≤–Ω–æ–π –æ—Ç–¥—ã—Ö",
            "ü§∏ –õ—ë–≥–∫–∞—è –∑–∞—Ä—è–¥–∫–∞ —É—Ç—Ä–æ–º",
            "ü•ó –õ—ë–≥–∫–∏–π —É–∂–∏–Ω –±–µ–∑ —Å–æ–ª–∏",
        ],
    },
    "—à–∞–ª—å–Ω–æ–π –≤–µ—Ç–µ—Ä": {
        "emoji": "üí®",
        "tips": [
            "üß£ –ó–∞—Ö–≤–∞—Ç–∏—Ç–µ —à–∞—Ä—Ñ",
            "üö∂ –ö–æ—Ä–æ—Ç–∫–∞—è –ø—Ä–æ–≥—É–ª–∫–∞",
            "üï∂Ô∏è –ó–∞—â–∏—Ç–∏—Ç–µ –≥–ª–∞–∑–∞ –æ—Ç –ø—ã–ª–∏",
            "üå≥ –ò–∑–±–µ–≥–∞–π—Ç–µ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤",
        ],
    },
    "–∂–∞—Ä–∞": {
        "emoji": "üî•",
        "tips": [
            "üí¶ –î–µ—Ä–∂–∏—Ç–µ –±—É—Ç—ã–ª–∫—É –≤–æ–¥—ã —Ä—è–¥–æ–º",
            "üß¢ –ù–æ—Å–∏—Ç–µ –≥–æ–ª–æ–≤–Ω–æ–π —É–±–æ—Ä",
            "üå≥ –ò—â–∏—Ç–µ —Ç–µ–Ω—å –≤ –ø–æ–ª–¥–µ–Ω—å",
            "‚ùÑÔ∏è –ü—Ä–æ—Ö–ª–∞–¥–Ω—ã–π –∫–æ–º–ø—Ä–µ—Å—Å –Ω–∞ –ª–æ–±",
        ],
    },
    "—Å—ã—Ä–æ—Å—Ç—å": {
        "emoji": "üíß",
        "tips": [
            "üëü –°–º–µ–Ω–∏—Ç–µ –æ–±—É–≤—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏",
            "üåÇ –î–µ—Ä–∂–∏—Ç–µ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –∑–æ–Ω—Ç",
            "üå¨Ô∏è –ü—Ä–æ–≤–µ—Ç—Ä–∏–≤–∞–π—Ç–µ –∂–∏–ª–∏—â–µ",
            "üß• –õ—ë–≥–∫–∞—è –Ω–µ–ø—Ä–æ–º–æ–∫–∞–µ–º–∞—è –∫—É—Ä—Ç–∫–∞",
        ],
    },
    "–ø–æ–ª–Ω–∞—è –ª—É–Ω–∞": {
        "emoji": "üåï",
        "tips": [
            "üìù –ó–∞–ø–∏—à–∏—Ç–µ —è—Ä–∫–∏–µ –∏–¥–µ–∏ –ø–µ—Ä–µ–¥ —Å–Ω–æ–º",
            "üßò –ú—è–≥–∫–∞—è –º–µ–¥–∏—Ç–∞—Ü–∏—è –≤–µ—á–µ—Ä–æ–º",
            "üåô –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ –ª—É–Ω—É –±–µ–∑ –≥–∞–¥–∂–µ—Ç–æ–≤",
            "üìö –ß—Ç–µ–Ω–∏–µ –Ω–∞ —Å–≤–µ–∂–µ–º –≤–æ–∑–¥—É—Ö–µ",
        ],
    },
    "–º–∏–Ω–∏-–ø–∞—Ä–∞–¥ –ø–ª–∞–Ω–µ—Ç": {
        "emoji": "‚ú®",
        "tips": [
            "üî≠ –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ –Ω–µ–±–æ –Ω–∞ —Ä–∞—Å—Å–≤–µ—Ç–µ",
            "üì∏ –°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—é –∑–∞–∫–∞—Ç–∞",
            "ü§î –ü–æ–¥—É–º–∞–π—Ç–µ –æ –±–µ—Å–∫—Ä–∞–π–Ω–∏—Ö –ø—Ä–æ—Å—Ç–æ—Ä–∞—Ö",
            "üé∂ –°–ª—É—à–∞–π—Ç–µ —Å–ø–æ–∫–æ–π–Ω—É—é –º—É–∑—ã–∫—É –≤–µ—á–µ—Ä–æ–º",
        ],
    },
}

ASTRO_HEALTH_FALLBACK: List[str] = [
    "üí§ –°–æ–±–ª—é–¥–∞–π—Ç–µ —Ä–µ–∂–∏–º —Å–Ω–∞: –ª–æ–∂–∏—Ç–µ—Å—å –Ω–µ –ø–æ–∑–∂–µ 23:00",
    "ü•¶ –í–∫–ª—é—á–∏—Ç–µ –≤ —Ä–∞—Ü–∏–æ–Ω —Å–≤–µ–∂–∏–µ –æ–≤–æ—â–∏ –∏ –∑–µ–ª–µ–Ω—å",
    "ü•õ –¢—ë–ø–ª—ã–π –Ω–∞–ø–∏—Ç–æ–∫ –≤–µ—á–µ—Ä–æ–º ‚Äî –±–µ–∑ –∫–æ—Ñ–µ–∏–Ω–∞",
    "üßò –õ—ë–≥–∫–∞—è —Ä–∞—Å—Ç—è–∂–∫–∞ —É—Ç—Ä–æ–º –∏ –≤–µ—á–µ—Ä–æ–º",
    "üö∂ –ü—Ä–æ–≥—É–ª–∫–∞ 20 –º–∏–Ω –Ω–∞ —Å–≤–µ–∂–µ–º –≤–æ–∑–¥—É—Ö–µ",
]

ASTRO_KEYWORDS = ["–ª—É–Ω–∞", "–Ω–æ–≤–æ–ª—É–Ω–∏–µ", "–ø–æ–ª–Ω–æ–ª—É–Ω–∏–µ", "—á–µ—Ç–≤–µ—Ä—Ç—å"]


# ‚îÄ‚îÄ —É—Ç–∏–ª–∏—Ç—ã LLM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _clean_lines(s: str) -> List[str]:
    """–ß–∏—Å—Ç–∏–º –æ—Ç–≤–µ—Ç LLM –≤ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ (—É–±–∏—Ä–∞–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é –∏ –ø—É—Å—Ç–æ—Ç—ã)."""
    raw = [ln.strip() for ln in (s or "").splitlines()]
    out: List[str] = []
    for ln in raw:
        if not ln:
            continue
        # —É–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –ª–∏–¥–µ—Ä—ã "1. ", "- " –∏ —Ç.–ø.
        out.append(ln.lstrip("‚Ä¢*-‚Äì‚Äî0123456789. ").strip())
    return out


def _try_openai(prompt: str, temperature: float, max_tokens: int) -> Optional[List[str]]:
    if not (OPENAI_KEY and OpenAI):
        return None
    try:
        client = OpenAI(api_key=OPENAI_KEY)
        resp = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=max_tokens,
            timeout=25,
        )
        text = (resp.choices[0].message.content or "").strip()
        lines = _clean_lines(text)
        if lines:
            log.info("LLM provider: OpenAI (%s)", OPENAI_MODEL)
            return lines
    except Exception as e:
        log.warning("OpenAI error: %s", e)
    return None


def _try_gemini(prompt: str, temperature: float, max_tokens: int) -> Optional[List[str]]:
    if not (GEMINI_KEY and genai):
        return None
    try:
        genai.configure(api_key=GEMINI_KEY)
        model = genai.GenerativeModel(GEMINI_MODEL)
        resp = model.generate_content(
            prompt,
            generation_config={
                "temperature": float(temperature),
                "max_output_tokens": int(max_tokens),
            }
        )
        # –≤ SDK –æ—Ç–≤–µ—Ç –≤ resp.text
        text = (getattr(resp, "text", None) or "").strip()
        lines = _clean_lines(text)
        if lines:
            log.info("LLM provider: Gemini (%s)", GEMINI_MODEL)
            return lines
    except Exception as e:
        log.warning("Gemini error: %s", e)
    return None


def _try_groq(prompt: str, temperature: float, max_tokens: int) -> Optional[List[str]]:
    if not (GROQ_KEY and Groq):
        return None
    try:
        client = Groq(api_key=GROQ_KEY)
        resp = client.chat.completions.create(
            model=GROQ_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=max_tokens,
            timeout=25,
        )
        text = (resp.choices[0].message.content or "").strip()
        lines = _clean_lines(text)
        if lines:
            log.info("LLM provider: Groq (%s)", GROQ_MODEL)
            return lines
    except Exception as e:
        log.warning("Groq error: %s", e)
    return None


def __llm_complete_with_fallback(prompt: str,
                                 temperature: float = 0.7,
                                 max_tokens: int = 600) -> Optional[List[str]]:
    """
    –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –∫ –º–æ–¥–µ–ª—è–º.
    –ü–æ—Ä—è–¥–æ–∫: OpenAI -> Gemini -> Groq. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –∏–ª–∏ None.
    """
    for fn in (_try_openai, _try_gemini, _try_groq):
        lines = fn(prompt, temperature, max_tokens)
        if lines:
            return lines
    return None


# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —É—Ç–∏–ª–∏—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω–∞ –≥–¥–µ-—Ç–æ –µ—â—ë)
def gpt_complete(prompt: str,
                 temperature: float = 0.7,
                 max_tokens: int = 600) -> str:
    lines = __llm_complete_with_fallback(prompt, temperature, max_tokens)
    return "\n".join(lines) if lines else ""


def _extract_summary_and_tips(lines: List[str],
                              culprit: str,
                              fallback_pool: List[str]) -> Tuple[str, List[str]]:
    """
    –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî summary (–µ—Å–ª–∏ –Ω–µ—Ç, –≥–µ–Ω–µ—Ä–∏–º –ª–æ–∫–∞–ª—å–Ω—ã–π).
    –°–ª–µ–¥—É—é—â–∏–µ 3 —Å—Ç—Ä–æ–∫–∏ ‚Äî —Å–æ–≤–µ—Ç—ã (–¥–æ–ø–æ–ª–Ω—è–µ–º –∏–∑ fallback_pool).
    """
    default_summary = f"–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {culprit}! üòâ"

    if not lines:
        return default_summary, random.sample(fallback_pool, min(3, len(fallback_pool)))

    summary = lines[0].strip() or default_summary
    tips = [ln for ln in lines[1:] if ln][:3]

    if len(tips) < 3:
        remain = [t for t in fallback_pool if t not in tips]
        tips += random.sample(remain, min(3 - len(tips), len(remain)))
        if len(tips) < 3 and fallback_pool:
            tips += random.sample(fallback_pool, 3 - len(tips))

    # –Ω–∞ —Å–ª—É—á–∞–π —Ä–µ–¥–∫–æ–≥–æ ¬´–º—É—Å–æ—Ä–∞¬ª
    tips = [t for t in tips if t and t != summary][:3]
    if len(tips) < 3 and fallback_pool:
        tips += random.sample(fallback_pool, min(3 - len(tips), len(fallback_pool)))
    return summary, tips[:3]


# ‚îÄ‚îÄ –ø—É–±–ª–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–∞–∫ —Ä–∞–Ω—å—à–µ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def gpt_blurb(culprit: str) -> Tuple[str, List[str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (summary: str, tips: List[str]) —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–µ–∂–Ω–µ–π –ª–æ–≥–∏–∫–∏:

    - –ï—Å–ª–∏ culprit ‚Äî ¬´–ø–æ–≥–æ–¥–Ω—ã–π¬ª –∏–∑ CULPRITS -> —Å–Ω–∞—á–∞–ª–∞ LLM, –µ—Å–ª–∏ –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª -> —Ñ–æ–ª–±—ç–∫ CULPRITS.
    - –ï—Å–ª–∏ culprit —Å–æ–¥–µ—Ä–∂–∏—Ç –õ—É–Ω—É/—Ñ–∞–∑—ã -> —Å–Ω–∞—á–∞–ª–∞ LLM, –µ—Å–ª–∏ –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª -> ASTRO_HEALTH_FALLBACK.
    - –ò–Ω–∞—á–µ -> —Å–Ω–∞—á–∞–ª–∞ LLM, –µ—Å–ª–∏ –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª -> ASTRO_HEALTH_FALLBACK.
    """
    culprit_lower = culprit.lower().strip()

    # 1) –ü–æ–≥–æ–¥–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä
    if culprit_lower in CULPRITS:
        tips_pool = CULPRITS[culprit_lower]["tips"]

        prompt = (
            f"–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ –æ–ø—ã—Ç–Ω—ã–π health coach —Å–æ –∑–Ω–∞–Ω–∏—è–º–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –º–µ–¥–∏—Ü–∏–Ω—ã. "
            f"–°–Ω–∞—á–∞–ª–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π –Ω–∞–ø–∏—à–∏: ¬´–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {culprit}!¬ª. "
            f"–ü–æ—Å–ª–µ —Ç–æ—á–∫–∏ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–π –ø–æ–∑–∏—Ç–∏–≤ (‚â§12 —Å–ª–æ–≤). "
            f"–ó–∞—Ç–µ–º –≤—ã–≤–µ–¥–∏ —Ä–æ–≤–Ω–æ 3 –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å–æ–≤–µ—Ç–æ–≤ (‚â§12 —Å–ª–æ–≤) —Å —ç–º–æ–¥–∑–∏, "
            f"—É—á–∏—Ç—ã–≤–∞—è –≤–ª–∏—è–Ω–∏–µ —Ñ–∞–∫—Ç–æ—Ä–∞ ¬´{culprit}¬ª –Ω–∞ —Å–∞–º–æ—á—É–≤—Å—Ç–≤–∏–µ."
        )
        lines = __llm_complete_with_fallback(prompt, temperature=0.7, max_tokens=600)
        if not lines:
            summary = f"–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {culprit}! üòâ"
            return summary, random.sample(tips_pool, min(3, len(tips_pool)))
        return _extract_summary_and_tips(lines, culprit, tips_pool)

    # 2) –ê—Å—Ç—Ä–æ-—Ñ–∞–∫—Ç–æ—Ä—ã (–õ—É–Ω–∞/—Ñ–∞–∑—ã)
    if any(k in culprit_lower for k in ASTRO_KEYWORDS):
        prompt = (
            f"–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ –æ–ø—ã—Ç–Ω—ã–π health coach. "
            f"–°–Ω–∞—á–∞–ª–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π –Ω–∞–ø–∏—à–∏: ¬´–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {culprit}!¬ª. "
            f"–ü–æ—Å–ª–µ —Ç–æ—á–∫–∏ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–π –ø–æ–∑–∏—Ç–∏–≤ (‚â§12 —Å–ª–æ–≤). "
            f"–ó–∞—Ç–µ–º –≤—ã–≤–µ–¥–∏ —Ä–æ–≤–Ω–æ 3 —Å—Ç—Ä–æ–∫–∏ —Å–æ–≤–µ—Ç–æ–≤ (—Å–æ–Ω, –ø–∏—Ç–∞–Ω–∏–µ, –¥—ã—Ö–∞–Ω–∏–µ, –ª—ë–≥–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å) "
            f"‚â§12 —Å–ª–æ–≤ —Å —ç–º–æ–¥–∑–∏, –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤–ª–∏—è–Ω–∏—è –õ—É–Ω—ã/—Ñ–∞–∑—ã."
        )
        lines = __llm_complete_with_fallback(prompt, temperature=0.7, max_tokens=600)
        if not lines:
            summary = f"–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {culprit}! üòâ"
            return summary, random.sample(ASTRO_HEALTH_FALLBACK, 3)
        return _extract_summary_and_tips(lines, culprit, ASTRO_HEALTH_FALLBACK)

    # 3) –ü—Ä–æ—á–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã
    prompt = (
        f"–î–µ–π—Å—Ç–≤—É–π –∫–∞–∫ –æ–ø—ã—Ç–Ω—ã–π health coach. "
        f"–°–Ω–∞—á–∞–ª–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π –Ω–∞–ø–∏—à–∏: ¬´–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {culprit}!¬ª. "
        f"–ü–æ—Å–ª–µ —Ç–æ—á–∫–∏ ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–π –ø–æ–∑–∏—Ç–∏–≤ (‚â§12 —Å–ª–æ–≤). "
        f"–ó–∞—Ç–µ–º –≤—ã–≤–µ–¥–∏ —Ä–æ–≤–Ω–æ 3 —Å—Ç—Ä–æ–∫–∏ —Å–æ–≤–µ—Ç–æ–≤ (—Å–æ–Ω, –ø–∏—Ç–∞–Ω–∏–µ, –¥—ã—Ö–∞–Ω–∏–µ, –ª—ë–≥–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å) "
        f"‚â§12 —Å–ª–æ–≤ —Å —ç–º–æ–¥–∑–∏ ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏."
    )
    lines = __llm_complete_with_fallback(prompt, temperature=0.7, max_tokens=600)
    if not lines:
        summary = f"–ï—Å–ª–∏ –∑–∞–≤—Ç—Ä–∞ —á—Ç–æ-—Ç–æ –ø–æ–π–¥—ë—Ç –Ω–µ —Ç–∞–∫, –≤–∏–Ω–∏—Ç–µ {culprit}! üòâ"
        # –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è ‚Äî –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –ø—É–ª
        pool = ASTRO_HEALTH_FALLBACK + sum((c["tips"] for c in CULPRITS.values()), [])
        return summary, random.sample(pool, 3) if len(pool) >= 3 else pool[:3]
    return _extract_summary_and_tips(lines, culprit, ASTRO_HEALTH_FALLBACK)
